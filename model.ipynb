{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Functions to simulate the final preprocessing pipeline\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def simulate_final_preprocessing(img_uint8, desired=64, padding=10):\n",
    "    \"\"\"\n",
    "    Mimic the digit_recognition preprocessing:\n",
    "      - Given a grayscale uint8 image (assumed shape (64,64)),\n",
    "      - Apply thresholding (using Otsu's method with inversion),\n",
    "      - Locate the bounding box of the white digit,\n",
    "      - Add padding and letterbox the cropped digit into a desired (64×64) image.\n",
    "    \"\"\"\n",
    "    # Apply Otsu's thresholding with inversion:\n",
    "    # (in your digit_recognition, THRESH_BINARY_INV+OTSU is used)\n",
    "    _, thresh = cv2.threshold(img_uint8, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find the bounding box of non-zero (white) pixels\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is None:\n",
    "        # If nothing is found, return a blank image.\n",
    "        return np.zeros((desired, desired), dtype=np.uint8)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    # Add some padding around the digit\n",
    "    x1 = max(x - padding, 0)\n",
    "    y1 = max(y - padding, 0)\n",
    "    x2 = min(x + w + padding, thresh.shape[1])\n",
    "    y2 = min(y + h + padding, thresh.shape[0])\n",
    "    \n",
    "    digit_roi = thresh[y1:y2, x1:x2]\n",
    "    \n",
    "    # Letterbox the digit_roi to a fixed size image (desired x desired)\n",
    "    h_roi, w_roi = digit_roi.shape\n",
    "    scale = min(desired / w_roi, desired / h_roi)\n",
    "    new_w = int(w_roi * scale)\n",
    "    new_h = int(h_roi * scale)\n",
    "    resized_digit = cv2.resize(digit_roi, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a blank (black) image and place the resized digit in the center\n",
    "    letterboxed = np.zeros((desired, desired), dtype=np.uint8)\n",
    "    x_offset = (desired - new_w) // 2\n",
    "    y_offset = (desired - new_h) // 2\n",
    "    letterboxed[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized_digit\n",
    "    \n",
    "    return letterboxed\n",
    "\n",
    "def final_preprocessing(image):\n",
    "    \"\"\"\n",
    "    Given an image (assumed to be a 64x64x1 normalized float image in [0,1]),\n",
    "    simulate the same steps as in digit_recognition.py:\n",
    "      1. Convert to uint8 [0,255]\n",
    "      2. Apply thresholding, cropping with padding, and letterboxing.\n",
    "      3. Return a normalized image with the same shape (64,64,1).\n",
    "    \"\"\"\n",
    "    # Remove the channel dimension temporarily and convert to uint8.\n",
    "    img_uint8 = (np.squeeze(image) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Simulate the preprocessing as in digit_recognition.py\n",
    "    processed = simulate_final_preprocessing(img_uint8, desired=64, padding=10)\n",
    "    \n",
    "    # Normalize back to [0, 1] and restore the channel dimension.\n",
    "    processed = processed.astype(np.float32) / 255.0\n",
    "    processed = np.expand_dims(processed, axis=-1)\n",
    "    return processed\n",
    "\n",
    "def batch_final_preprocessing(X):\n",
    "    \"\"\"\n",
    "    Process an entire dataset X (assumed shape: (N, 64, 64, 1)) by applying\n",
    "    final_preprocessing to every image.\n",
    "    \"\"\"\n",
    "    processed_images = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        processed_images[i] = final_preprocessing(X[i])\n",
    "    return processed_images\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load and Prepare the Data (Kaggle's Digit Recognizer / MNIST)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Adjust the file path to your train.csv file\n",
    "data_path = \"drive/MyDrive/digit_recognizer/train.csv\"\n",
    "train_df = pd.read_csv(data_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = train_df.drop(\"label\", axis=1)\n",
    "y = train_df[\"label\"]\n",
    "\n",
    "# Normalize pixel values and reshape from flat vectors to 28×28×1 images\n",
    "X = X / 255.0\n",
    "X = X.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Resize to 64x64\n",
    "# -----------------------------------------------------------------------------\n",
    "def resize_to_64(images):\n",
    "    n = images.shape[0]\n",
    "    X_64 = np.zeros((n, 64, 64, 1), dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        # Get the 2D image from the single channel (28×28)\n",
    "        img_28 = images[i, :, :, 0]\n",
    "        # Resize with INTER_AREA interpolation for good quality\n",
    "        img_64 = cv2.resize(img_28, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        X_64[i, :, :, 0] = img_64\n",
    "    return X_64\n",
    "\n",
    "X_64 = resize_to_64(X)\n",
    "print(\"After resizing, X_64 shape:\", X_64.shape)  # Expected: (num_samples, 64, 64, 1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Simulate the final preprocessing pipeline on the training images\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Applying final preprocessing to training images to simulate scanning...\")\n",
    "X_final = batch_final_preprocessing(X_64)\n",
    "print(\"X_final shape:\", X_final.shape)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_cat = to_categorical(y, num_classes=10)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train/Validation Split\n",
    "# -----------------------------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_final, y_cat, test_size=0.1, random_state=2)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build an Improved CNN Model\n",
    "# -----------------------------------------------------------------------------\n",
    "# (We add BatchNormalization layers to help learning and use similar dropout.)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model with RMSprop optimizer (adjust learning rate as needed)\n",
    "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data Augmentation\n",
    "# -----------------------------------------------------------------------------\n",
    "# Here we keep augmentation parameters; you might further tweak these\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=5,  # optional: add slight shear\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Callbacks: Learning Rate Reduction and Early Stopping\n",
    "# -----------------------------------------------------------------------------\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                 patience=3,\n",
    "                                 verbose=1,\n",
    "                                 factor=0.5,\n",
    "                                 min_lr=1e-5)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train the Model\n",
    "# -----------------------------------------------------------------------------\n",
    "epochs = 50  # increase epochs to help convergence\n",
    "batch_size = 86\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                    callbacks=[lr_reduction, early_stopping],\n",
    "                    verbose=2)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot Training History\n",
    "# -----------------------------------------------------------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "ax1.set_title(\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "ax2.set_title(\"Accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Save the Model\n",
    "# -----------------------------------------------------------------------------\n",
    "save_path = \"drive/MyDrive/handwritten_digit_cnn_improved.h5\"\n",
    "model.save(save_path)\n",
    "print(f\"Model saved as '{save_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
